import time
from urllib.parse import urljoin

import requests

from app import config
from app import pyppeteer
from app import storage
from app.logger import logger

BASE_URL = "https://app.banner.pdx.edu/StudentRegistrationSsb/ssb/"
INIT_URL = urljoin(BASE_URL, "term/termSelection?mode=search")
CLASS_URL = urljoin(BASE_URL, "classSearch/classSearch")
TERMS_URL = urljoin(BASE_URL, "classSearch/getTerms")
SEARCH_URL = urljoin(BASE_URL, "term/search?mode=search")
SCHEDULE_URL = urljoin(BASE_URL, "searchResults/searchResults")
SUBJECTS_URL = urljoin(BASE_URL, "classSearch/get_subject")


def authenticate_current_session(term, unique_session_id, cookies):
    """Make a POST request that will authenticate the user with this JSESSIONID
    and uniqueSessionId and enable the sched_page GET request to return JSON

    :param term: Term dictionary with code and description keys.
    :param unique_session_id: Unique session id generated by the page which
                              allows authentication.
    :param cookies: Cookies of the previous requests.
    """

    payload = {
        "dataType": "json",
        "endDatepicker": "",
        "startDatepicker": "",
        "studyPath": "",
        "studyPathText": "",
        "term": term["code"],
        "uniqueSessionId": unique_session_id,
    }
    return requests.post(
        SEARCH_URL, headers={"referer": INIT_URL}, cookies=cookies, params=payload
    )


def get_schedule_json(subject, term, unique_session_id, cookies):
    """Gets JSON representation of the subject for the specified term.

    :param subject: The subject in question.
    :param term: The term in question.
    :param unique_session_id: Unique session id generated by the page which
                              allows authentication.
    :param cookies: Cookies of the previous requests.
    """

    payload = {
        "txt_subject": subject["code"],
        "txt_term": term["code"],
        "startDatepicker": "",
        "endDatepicker": "",
        "uniqueSessionId": unique_session_id,
        "pageOffset": "0",
        "pageMaxSize": "100",
        "sortColumn": "subjectDescription",
        "sortDirection": "asc",
    }
    res = requests.get(
        SCHEDULE_URL, headers={"referer": CLASS_URL}, cookies=cookies, params=payload
    )

    if res.ok:
        return res.json()

    return None


def get_subjects(cookies, unique_session_id, term_date):
    """Gets the subjects that are available for a particular term.

    :param cookies: Cookies needed to authenticate the request.
    :param unique_session_id: Parameter needed to authenticate the request.
    :param term_date: term Where the subjects will be searched for.
    :returns: JSON with list of subjects
    """

    payload = {
        "uniqueSessionId": unique_session_id,
        "dataType": "json",
        "searchTerm": "",
        "term": term_date,
        "offset": "1",
        "max": config.MAX_SUBJECTS,
        # Query string params expect a timestamp with extra 3 digits
        "_:": str(int(time.time() * 1000)),
    }
    res = requests.get(SUBJECTS_URL, cookies=cookies, params=payload)

    if res.ok:
        return res.json()

    return None


def get_terms(cookies, unique_session_id):
    """Gets JSON with list of terms in the form {code : description}

    :param cookies: Cookies needed to authenticate the request
    :param unique_session_id: Parameter needed to authenticate the request
    :returns: JSON with list of the terms
    """

    payload = {
        "uniqueSessionId": unique_session_id,
        "dataType": "json",
        "searchTerm": "",
        "offset": "1",
        "max": config.MAX_TERMS,
    }
    res = requests.get(TERMS_URL, cookies=cookies, params=payload)

    if res.ok:
        return res.json()

    logger.info("No terms were found.")
    return None


async def run():
    browser = await pyppeteer.initialize()
    page = await pyppeteer.get_page(browser)

    timestamp = await page.evaluate("new Date().toISOString()")
    payload = {"timestamp": timestamp}
    logger.debug(timestamp)
    logger.debug("Finished")
    storage.upload_to_bucket(payload)
    return payload


async def crawl():
    browser = await pyppeteer.initialize()
    page = await pyppeteer.get_page(browser)
    session_id, unique_session_id = await pyppeteer.get_tokens(browser)

    if None in (session_id, unique_session_id):
        browser.close()
        return

    cookies = dict(JSESSIONID=session_id)
    terms = get_terms(cookies, unique_session_id)

    terms_json = []
    for term in terms:
        subjects = get_subjects(cookies, unique_session_id, term["code"])
        subjects_json = await get_subjects_json(subjects, term, cookies, page)
        terms_json.append(subjects_json)

    print(f"for debugging: length of subjects: {len(subjects_json)}")
    await browser.close()


async def get_subjects_json(subjects, term, cookies, page):
    subjects_json = []
    for idx, subject in enumerate(subjects):
        logger.debug(
            "Crawling subject",
            extra={
                "subject": subject["description"],
                "subjectIndex": idx + 1,
                "totalSubjects": len(subjects),
                "term": term["description"],
            },
        )

        unique_session_id = await pyppeteer.get_unique_session_id(page)
        authenticate_current_session(term, unique_session_id, cookies)
        sched_json = get_schedule_json(subject, term, unique_session_id, cookies)

        if "data" in sched_json.keys():
            subjects_json.append(sched_json["data"])
        else:
            logger.warning(
                "No course data found.", extra={"subject": subject["description"]}
            )

    return subjects_json
